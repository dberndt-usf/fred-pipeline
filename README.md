# ğŸ§® FRED Data Pipeline

**A lightweight, end-to-end Python data pipeline** demonstrating the full data lifecycle:
fetching economic data from the [Federal Reserve Economic Data (FRED)](https://fred.stlouisfed.org/) API, 
curating and storing it locally, loading it into a DuckDB warehouse, 
and running analytic SQL queries â€” including multi-lag and rolling correlations between **GDP** and **DJIA**.

---

## ğŸ¯ Learning Objectives

Students will learn how to:

1. **Extract** data from a REST API (FRED) using Python and `requests`.  
2. **Transform & curate** data from raw JSON to clean CSV.  
3. **Load & analyze** data in an embedded analytics database (DuckDB).  
4. **Explore correlations** between stock market and GDP data using SQL lag and window functions.  

---

## ğŸ§± Directory Structure

```
fred-pipeline/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/          # Raw JSON files from the API
â”‚   â”œâ”€â”€ curated/      # Clean CSVs ready for analytics
â”‚   â””â”€â”€ warehouse/    # DuckDB database (.duckdb)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ fred_fetch.py       # Fetches series from FRED API
â”‚   â”œâ”€â”€ duckdb_utils.py     # Loads and queries DuckDB
â”‚   â””â”€â”€ duckdb_queries.py   # Analytic SQL (aggregations, lag, rolling correlation)
â”‚
â”œâ”€â”€ main.py           # Orchestration script (runs all pipeline stages)
â”œâ”€â”€ .env              # Contains your FRED_API_KEY
â”œâ”€â”€ requirements.txt  # Python dependencies
â””â”€â”€ README.md         # This file
```

---

## âš™ï¸ Setup Instructions

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourname/fred-pipeline.git
   cd fred-pipeline
   ```

2. **Create a virtual environment**
   ```bash
   python -m venv .venv-pipe
   source .venv-pipe/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set your FRED API key**

   Create a `.env` file at the project root:
   ```bash
   FRED_API_KEY=your_api_key_here
   ```

   Obtain your key from [FREDâ€™s Developer Portal](https://fred.stlouisfed.org/docs/api/fred/).

---

## ğŸš€ Running the Pipeline

```bash
python main.py
```

This will:

1. Fetch **GDP** and **DJIA** data from FRED (`scripts/fred_fetch.py`)  
2. Save raw JSON and curated CSV files under `/data/`  
3. Load those CSVs into DuckDB (`scripts/duckdb_utils.py`)  
4. Create quarterly tables and compute:  
   - Same-quarter correlation  
   - 1-quarter lag correlation  
   - 2-quarter lag correlation  
   - 4-quarter rolling correlation  

---

## ğŸ“Š Sample Output

```
ğŸ“Š Correlation results:
   corr_same_quarter  corr_lag1  corr_lag2
0             0.9510      0.9484      0.9442

ğŸ“ˆ Rolling correlation (4-quarter window):
   quarter_start  rolling_corr
57    2024-04-01      0.896810
58    2024-07-01      0.910782
59    2024-10-01      0.922337
60    2025-01-01      0.971350
61    2025-04-01      0.172703
```

---

## ğŸ§  Pedagogical Notes

| Stage | Tool | Concept | Deliverable |
|-------|------|----------|--------------|
| **1ï¸âƒ£ Extract** | Python + FRED API | REST, JSON, Environment Variables | `/data/raw/` |
| **2ï¸âƒ£ Transform** | pandas | Data cleaning, CSV export | `/data/curated/` |
| **3ï¸âƒ£ Load** | DuckDB | SQL table creation, in-process OLAP | `/data/warehouse/fred.duckdb` |
| **4ï¸âƒ£ Analyze** | SQL analytics | Multi-lag correlation, rolling correlation | printed results |

---

## ğŸ§© Requirements

```
requests
pandas
python-dotenv
duckdb
```

*(Optional for visualization)*  
```
streamlit
```

---

## ğŸ’¡ Next Steps

- Add **Streamlit dashboards** to visualize GDP vs DJIA and rolling correlations.  
- Include **more FRED series** (CPI, unemployment, Fed Funds Rate) for macro comparisons.  
- Integrate **MLflow** to track correlation results and model experiments.  


